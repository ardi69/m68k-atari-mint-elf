Index: include/bits/sched.h
===================================================================
--- include/bits/sched.h	(Revision 702)
+++ include/bits/sched.h	(Arbeitskopie)
@@ -21,8 +21,9 @@
 #ifndef _SCHED_H
 # error "Never include <bits/sched.h> directly; use <sched.h> instead."
 #endif
+#ifndef _BITS_SHED_H
+#define _BITS_SHED_H
 
-
 /* Scheduling algorithms.  */
 #define SCHED_OTHER	0
 #define SCHED_FIFO	1
@@ -33,3 +34,6 @@
 {
   int __sched_priority;
 };
+#define __sched_param sched_param
+
+#endif /* _BITS_SHED_H */
Index: include/stdlib.h
===================================================================
--- include/stdlib.h	(Revision 702)
+++ include/stdlib.h	(Arbeitskopie)
@@ -81,7 +81,7 @@
 extern double strtod (__const char *__restrict __nptr,
 		      char **__restrict __endptr) __THROW;
 
-#ifdef	__USE_ISOC99
+/*#ifdef	__USE_ISOC99*/
 /* Likewise for `float' and `long double' sizes of floating-point numbers.  */
 extern float strtof (__const char *__restrict __nptr,
 		     char **__restrict __endptr) __THROW;
@@ -88,7 +88,7 @@
 
 extern long double strtold (__const char *__restrict __nptr,
 			    char **__restrict __endptr) __THROW;
-#endif
+/*#endif*/
 
 /* Convert a string to a long integer.  */
 extern long int strtol (__const char *__restrict __nptr,
Index: mintlib/EXTRAFILES
===================================================================
--- mintlib/EXTRAFILES	(Revision 702)
+++ mintlib/EXTRAFILES	(Arbeitskopie)
@@ -11,6 +11,7 @@
 _itoa.h math_private.h math_ldbl.h atomicity.h atomicity-68020.h errbase.h \
 gensys stksiz.h sysdep.h lib.h libc-symbols.h \
 machine-gmon.h memcopy.h profil-counter.h malloc_int.h \
+spin_lock.h \
 syscalls.h syscalls.list test-assert-perr.c test-assert.c test-atexit.c \
 test-atexit.expect test-ctype.c test-ctype1.c test-ctype1.expect \
 test-dirent.args test-dirent.c test-mallocbug.c test-seekdir.c test-setjmp.c \
Index: mintlib/malloc.c
===================================================================
--- mintlib/malloc.c	(Revision 702)
+++ mintlib/malloc.c	(Arbeitskopie)
@@ -12,11 +12,11 @@
 #include <string.h>
 #include <assert.h>
 #include <unistd.h>
-#include <osbind.h>
+#include <mintbind.h>
 #include "lib.h"
 #include "malloc_int.h"
+#include "spin_lock.h"
 
-
 /* CAUTION: use _mallocChunkSize() to tailor to your environment,
  *          do not make the default too large, as the compiler
  *          gets screwed on a 1M machine otherwise (stack/heap clash)
@@ -39,7 +39,14 @@
 /* linked list of free blocks struct defined in lib.h */
 struct mem_chunk _mchunk_free_list = { VAL_FREE, NULL, 0L };
 
+/* threads shares the memory. ergo each thread can use malloc
+   to make malloc thread safe we use a simple spin-lock        */
+_SPIN_MUTEX_T __malloc_mutex = _SPIN_MUTEX_INIT;
 
+#define MALLOC_SPIN_LOCK() while(__atomic_test_and_set(&__malloc_mutex, __ATOMIC_SEQ_CST)) Syield()
+#define MALLOC_SPIN_UNLOCK()  do { __malloc_mutex = 0; } while(0)
+
+
 void *
 __malloc(size_t n)
 {
@@ -46,6 +53,8 @@
 	struct mem_chunk *p, *q;
 	unsigned long sz;
 
+	_SPIN_LOCK(__malloc_mutex);
+
 	/* add a mem_chunk to required size and round up */
 	n = (n + sizeof(struct mem_chunk) + (MALLOC_ALIGNMENT - 1)) & ~(MALLOC_ALIGNMENT - 1);
 
@@ -85,8 +94,10 @@
 		}
 
 		q = (struct mem_chunk * ) __sbrk(sz);
-		if (((long) q) == -1) /* can't alloc any more? */
+		if (((long) q) == -1) { /* can't alloc any more? */
+			_SPIN_UNLOCK(__malloc_mutex);
 			return NULL;
+		}
 
 		/* Note: q may be below the highest allocated chunk */
 		p = &_mchunk_free_list;
@@ -132,6 +143,8 @@
 	q->next = NULL;	
 	q++; /* hand back ptr to after chunk desc */
 
+	_SPIN_UNLOCK(__malloc_mutex);
+
 	if (ZeroMallocs)
 		memset(q, 0, (size_t)(n - sizeof(struct mem_chunk)));
 
@@ -157,6 +170,8 @@
 
 	r->valid = VAL_FREE;
 
+	_SPIN_LOCK(__malloc_mutex);
+
 	/* stick it into free list, preserving ascending address order */
 	o = NULL;
 	p = &_mchunk_free_list;
@@ -197,6 +212,7 @@
 			else
 				p->next = r;
 
+			_SPIN_UNLOCK(__malloc_mutex);
 			return;
 		}
 
@@ -234,7 +250,7 @@
 		}
 	}
 	else
-        {
+	{
 		s = (struct mem_chunk * )(((long) r) + r->size);
 		if ((!_split_mem) && _heapbase != NULL &&
 		    s >= (struct mem_chunk *) _heapbase &&
@@ -250,5 +266,6 @@
 		else
 			p->next = r;
 	}
+	_SPIN_UNLOCK(__malloc_mutex);
 }
 weak_alias(__free, free)
Index: mintlib/realloc.c
===================================================================
--- mintlib/realloc.c	(Revision 702)
+++ mintlib/realloc.c	(Arbeitskopie)
@@ -9,10 +9,16 @@
 #include <string.h>
 #include <assert.h>
 #include <unistd.h>
+#include <mintbind.h> // for Syield
 #include "lib.h"
 #include "malloc_int.h"
+#include "spin_lock.h"
 
+/* threads shares the memory. ergo each thread can use malloc
+   to make malloc thread safe we use a simple spin-lock        */
+extern _SPIN_MUTEX_T __malloc_mutex;
 
+
 void *
 __realloc (void *r, size_t n)
 {
@@ -58,6 +64,8 @@
 		/* block too small, get new one */
 		struct mem_chunk *q, *s, *t;
 
+		_SPIN_LOCK(__malloc_mutex);
+
 		q = &_mchunk_free_list;
 		t = _mchunk_free_list.next;
 		while (t && t < p)
@@ -77,11 +85,16 @@
 			q->next = t->next;
 			t->size = 0;
 			t->next = NULL;
+
+			_SPIN_UNLOCK(__malloc_mutex);
+
 		}
 		else
 		{
 			void *newr;
 
+			_SPIN_UNLOCK(__malloc_mutex);
+
 			newr = __malloc(n);
 			if (newr)
 			{
Index: mintlib/spin_lock.h
===================================================================
--- mintlib/spin_lock.h	(nicht existent)
+++ mintlib/spin_lock.h	(Arbeitskopie)
@@ -0,0 +1,13 @@
+/*
+ * spin_lock
+ */
+#ifndef _SPIN_LOCK_H
+#define _SPIN_LOCK_H
+
+#define _SPIN_MUTEX_T char
+#define _SPIN_MUTEX_INIT (0)
+#define _SPIN_LOCK(SPIN_MUTEX) while(__atomic_test_and_set(&SPIN_MUTEX, __ATOMIC_SEQ_CST)) Syield()
+#define _SPIN_UNLOCK(SPIN_MUTEX)  do { SPIN_MUTEX = 0; } while(0)
+
+
+#endif /* _SPIN_LOCK_H */
